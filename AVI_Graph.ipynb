{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVI Graph\n",
    "1. Objetivo\n",
    "2. Problemas a serem resolvidos por meio desse grafo\n",
    "3. Materiais \n",
    "4. Métodos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos\n",
    "O objetivo principal deste projeto é construir um grafo por meio das conversas entre usuário e AVI afim de aprender a estrutura dessas conversas, predizer os possíveis perguntas do usuário considerando a primeira pergunta, sugerir respostas alternativas e achar os fluxos mais úteis em um atendimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Os problemas que pretendem-se resolver\n",
    "\n",
    "Nessa seção vamos apresentar três problemas que pretendemos resolver.\n",
    "\n",
    "### Primeiro caso:\n",
    "Sabemos que por falta de conhecimento do domínio/produtos do banco, alguns usuários não sabem a melhor forma de explicar o problema para o atendente. Por isso, acontecem algumas conversas redundantes até o AVI ou atendente conseguir achar o problema e resolvé-lo. No caso do AVI, achar o problema verdadeiro pode demorar. Gostaríamos de utilizar os dados das perguntas semelhantes e achar a duração mais curta que consegue-se achar o problema e oferecer uma solução.\n",
    "\n",
    "<img src=\"Img/Img01.png\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segundo caso:\n",
    "\n",
    "Tendo a primeira pergunta, gostaríamos de predizer as próximas perguntas do usuário e mostrar perguntas/soluções subsequentes a fim de <b><u>facilitar</u></b> o processo ou <b><u>adiantar</u></b> a solução para o usuário.\n",
    "\n",
    "<img src=\"Img/Img02.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terceiro caso:\n",
    "\n",
    "Sugerir opções relevantes pode ajuar o cliuente para conhecer melhor os produtos do banco.\n",
    "\n",
    "<img src=\"Img/Img03.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Materias:\n",
    "\n",
    "Pedem-se usar duas bases de dados: \n",
    "   1. Base das conversas do usuário com o AVI; \n",
    "   2. Base das conversas do usuário com especialista;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos\n",
    "\n",
    "Para resolver os casos acima, usamos uma abordagem voltada à teroria de grafos. Essa solução por si consegue resolver todos os problemas acima. No entanto, no futuro algoritmos de aprendizagem de máquina tais como graph-convolutional neural networks, graph generative adversarial networks podem ser utilizadas para aprender a estrutura desse grafo e produzir novas soluções para diversos problemas interessantes.\n",
    "\n",
    "### Proposta\n",
    "\n",
    "Nessa seção vamos apresentar a solução sugerida. Essa solução é baseada em seguintes étapas:\n",
    "\n",
    "1. Construa uma estrutura inicial das conversas em forma de árvore;\n",
    "2. Cria relações da forma da cadeia de Markov: \n",
    "\n",
    "$$ P(intenção1, intenção2,... | pergunta1, pergunta 2,...)... = P(intenção1|pergunta1)P(intenção2|pergunta2)... $$\n",
    "\n",
    "3. Adicionando novas arestas chamadas <b>\"dummy edges\"</b>, crie relações entre os vertíces relacionados às perguntas ( cada árvore representa uma conversa ) no espaço semântico;\n",
    "4. Reduza o grafo eleminando os vértices que semanticamente são similares e tem intenções iguais\n",
    "5. Calcula $ n $ matrizes das distâncias de <b> passeio aleatório </b> $ RW $ de tamanho $ l = 0,1,2,....n $ entre cada um dos vértices onde $ n = max (l) $;\n",
    "6. Use as distâncias calculadas para calcular o caminho mais curto entre todos os vérticis relacionados às perguntas.\n",
    "\n",
    "A seguir vamos explicar cada um dessas etapas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Construir uma estrutura inicial das conversas em forma de árvore\n",
    "\n",
    "Vamos começar com um exemplo.\n",
    "\n",
    "<img src=\"Img/Img04.png\">\n",
    "\n",
    "<img src=\"Img/Img05.png\">\n",
    "\n",
    "### 2. Criar relações de forma da cadeia de Markov entre perguntas e as intenções\n",
    "\n",
    "<img src=\"Img/Img06.png\">\n",
    "\n",
    "A estrutura das conversas mostra que cada pergunta pode ou não depender da intenção da pergunta anterior. Uma vez que por enquanto o AVI não considera o contexto (as conversas anteriores) a última pergunta é suficiente para predizer a intenção. Assim, a cadeia de Markov define a estrutura probabilística do problema da melhor forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import os\n",
    "from pyemd import emd\n",
    "from gensim.similarities import WmdSimilarity\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#!pip3 install pyemd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vfcarida/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (16,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "chat = pd.read_csv(\"conversas.csv\" , error_bad_lines=False,  encoding=\"ISO-8859-1\", sep = ';')\n",
    "\n",
    "session_id=chat[\"session_id\"]\n",
    "interaction_id=chat[\"interaction_id\"]\n",
    "user_message=chat[\"user_message\"]\n",
    "intention_name=chat[\"intention_name\"]\n",
    "system_reply=chat[\"system_reply\"]\n",
    "\n",
    "conversations = pd.DataFrame()\n",
    "conversations[\"sessionId\"] = session_id\n",
    "conversations[\"interaction_id\"] = interaction_id\n",
    "conversations[\"user_message\"] = user_message\n",
    "conversations[\"intention_name\"] = intention_name\n",
    "conversations[\"system_reply\"] = system_reply\n",
    "\n",
    "\n",
    "conversations = conversations.dropna(how=\"any\")\n",
    "\n",
    "conversations = conversations.drop_duplicates(['interaction_id'], keep='last')\n",
    "\n",
    "## Sorting the dataframe based on Session Id\n",
    "#conversations.sort_values(['sessionId'], ascending=[True])\n",
    "conversations = conversations.sort_values(['sessionId'], ascending=[True]).drop_duplicates(['interaction_id'], keep='last')\n",
    "\n",
    "## Deleting rows related to \"Boas vindas\"\n",
    "conversations = conversations[conversations[\"intention_name\"] != \"boas vindas\"]\n",
    "\n",
    "\n",
    "### joining the conversations related to the same session\n",
    "sessions = []\n",
    "previousSessionId=0\n",
    "session = []\n",
    "loopCounter = 0\n",
    "for index, item in conversations.iterrows():\n",
    "    if loopCounter == 0:\n",
    "        previousSessionId = item[\"sessionId\"] \n",
    "    if previousSessionId == item[\"sessionId\"]:\n",
    "        session.append(item[\"sessionId\"])\n",
    "        #print(\"appended\")\n",
    "    else:\n",
    "        sessions.append(session)\n",
    "        session = []\n",
    "    previousSessionId = item[\"sessionId\"]\n",
    "    loopCounter += 1\n",
    "\n",
    "conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Dummy edges\n",
    "Nessa etapa existem várias árvores que representam diversas conversas. Uma vez que algumas perguntas em conversas distintas tem intenções iguais, existem arestas que conectam essas árvores. Todavia, essas relações são somente estruturais. Para resolver os primeiro e terceiro problemas, é necessário considerar relações semânticas entre as perguntas.\n",
    "\n",
    "<b>Mas como criar essas relações entre dados estruturais e o espaço semantico?</b>\n",
    "\n",
    "Para fazer isso, propomos adicionar novas arestas chamadas <b>\"dummy edges\"</b>. Essas arestas não existem no grafo original mas ajudam a levar os atributis (attribute graph) dos vértices a consideração. Nessa etapa propõe-se o seguinte algoritmo:\n",
    "\n",
    "1. Atribua pesos iguais para todas as arestas $ W_{i,j}  = 1$\n",
    "2. Ache a distância semântica $ d_{i,j} $ entre todos os vértices do grafo, $ i $ e $ j $\n",
    "3. Crie arestas entre os vérticies e atribua pesos de forma $ W_{i,j} = 1 - \\frac{d_{i,j}}{D} $ onde $ D $ é maior distância entre dois vértices no grafo, $ W_{i,j}$ é a probabilidade de chegar de $i$ a $j$. Nessa equação $ i $ e $ j $ não são vértices da mesma àrvore (conversa). Chamamos essas arestas de \"dummy edges\". Já que os \"dummy edges\" não fazem parte do grafo original, sempre a preferênia de escolher um caminho entre dois vérticies é o caminho do grafo original. Isso justifica a existência de 1 na equação $ W_{i,j} = 1 - \\frac{d_{i,j}}{D} $.\n",
    "\n",
    "<img src=\"Img/Img07.png\">\n",
    "   \n",
    "Nesse exemplo $ d_{1,6} $ refere a distância semântica entre vértice número 1 e 6. Assim formamos $ W_{1,6} = 1 + d_{1,6} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "## Deleting the punctuation from conversations\n",
    "sentences = []\n",
    "for line in sessionText:\n",
    "    line = \"\".join(l for l in line if l not in string.punctuation)\n",
    "    sentences.append(line.lower().split())\n",
    "    #sentences.append(line.lower())    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training Word2Vec on conversations in order to get the semantic similarity for conversation words \n",
    "chatModel = Word2Vec(sentences, min_count=1)\n",
    "\n",
    "## Testing the trained model\n",
    "\n",
    "chatModel.wv.most_similar(\"depositado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating conversation tree using adjecency matrix\n",
    "\n",
    "\n",
    "intentionsList=[]\n",
    "counter = 0\n",
    "for key in intentions:\n",
    "     intentionsList.append(key)\n",
    "\n",
    "\n",
    "\n",
    "nodeIndex=0\n",
    "dummynodeIndex=0\n",
    "nodeIndexLabel = []\n",
    "# 348 : number of existing intentions\n",
    "# 261783 : number of conversations\n",
    "# WE USE THE FIRST 35000 SAMPLES TO LEARN\n",
    "\n",
    "\n",
    "#### Creating the matrix of only 35000 conversations\n",
    "previousSessionId = None\n",
    "conversationLen= len(conversations[0:35000])\n",
    "adjMatrix = np.zeros((conversationLen , conversationLen + len(intentions)))\n",
    "\n",
    "for index ,chat in conversations[0:conversationLen].iterrows():\n",
    "    currentId = chat[\"sessionId\"]\n",
    "    ## setting the intention in adj matrix\n",
    "    intentionIndex = intentionsList.index(chat[\"intention_name\"])\n",
    "    adjMatrix[nodeIndex][conversationLen + intentionIndex -1] = 1\n",
    "    \n",
    "    ## setting the chats tree structures in adj matrix\n",
    "    if previousSessionId == None:\n",
    "        previousSessionId = chat[\"sessionId\"]\n",
    "    if previousSessionId == currentId:\n",
    "        adjMatrix[nodeIndex-1][nodeIndex] = 1\n",
    "        \n",
    "    previousSessionId = currentId\n",
    "    nodeIndex += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating conversation tree using List (more economic!!!!!) and adding DUMMY NODES\n",
    "nodeIndex=0\n",
    "nodeIndexLabel = []\n",
    "\n",
    "previousSessionId = None\n",
    "\n",
    "adjList = []\n",
    "conversationLen= len(conversations[0:10000])\n",
    "dummynodeIndex = conversationLen\n",
    "# 2 * conversationLen was generated in order to have both semantic and structural data\n",
    "\n",
    "for index ,chat in conversations[0:conversationLen].iterrows():\n",
    "    currentId = chat[\"sessionId\"]\n",
    "    ## setting the intention in adjcency list\n",
    "    intentionIndex = intentionsList.index(chat[\"intention_name\"])\n",
    "    ## WE DO NOT NEED \"dummy nodes\" BECAUSE IT WAS REPLACED WITH DUMMY EDGES\n",
    "    ######adjList.append((nodeIndex , conversationLen + dummynodeIndex + intentionIndex))\n",
    "    ##\n",
    "    \n",
    "    adjList.append((nodeIndex , conversationLen + intentionIndex))\n",
    "    \n",
    "    ## setting the dummy node related to node attribute (semantic vector)\n",
    "    ######adjList.append((nodeIndex, dummynodeIndex + nodeIndex))\n",
    "    ##\n",
    "    adjList.append((nodeIndex, nodeIndex))\n",
    "    ## setting the chats tree structures in adj matrix\n",
    "    \n",
    "    if previousSessionId == currentId:\n",
    "        adjList.append((nodeIndex-1,nodeIndex))\n",
    "    if previousSessionId == None:\n",
    "        previousSessionId = chat[\"sessionId\"]\n",
    "        \n",
    "    previousSessionId = currentId\n",
    "    nodeIndex += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating the semantic distance between conversations\n",
    "## CAUTION!!: NO NEED TO RUN THIS CODE! THIS PART HAS ALREADY BEEN DONE AND SAVED IN A TEXT FILE. Running this file\n",
    "## will take 2 dayw! So, use the \"chatSemanticSimilarity.txt\" file!\n",
    "## Calculating the semantic distance between conversations\n",
    "import threading\n",
    "usersMessagesDistances = []\n",
    "\n",
    "def getDistance(counter,i,str1,str2):\n",
    "    distance = chatModel.wmdistance(str1,str2)\n",
    "    usersMessagesDistances.append((counter, i ,distance))\n",
    "    if len(usersMessagesDistances)%10000000==0:\n",
    "        with open(\"chatSemanticSimilarities.txt\",\"w\") as writer:\n",
    "            for item in usersMessagesDistances:\n",
    "                writer.write(str(item))\n",
    "                writer.write(\"\\n\")\n",
    "\n",
    "counter = 0\n",
    "for index ,chat in conversations[0:conversationLen].iterrows():\n",
    "    for i in range(counter, conversationLen):\n",
    "        arg = (counter, i , chat[\"user_message\"].lower(),list(conversations['user_message'])[i].lower())\n",
    "        threading.Thread(target = getDistance , args = arg).start()\n",
    "    counter+=1\n",
    "    #if counter%100==0:\n",
    "    #print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To read the the message disatnces from file\n",
    "usersMessagesDistances = []\n",
    "with open('chatSemanticSimilarities.txt') as f:\n",
    "    for item in f:\n",
    "        usersMessagesDistances = item.split(\";\")\n",
    "        #print(usersMessagesDistances[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Redução do grafo\n",
    "\n",
    "Neste passo o objetivo é reduzir o tamanho do grafo afim de ter uma estrutura numérica que passa maior informação tendo o menor tamanho. Escolhemos um parâmetro <b>$ α $</b> como limiar. Essa fase possui duas etapas:\n",
    "1. Eliminar os vértices inúteis:\n",
    "\n",
    "    -- Se o peso <b>$ W_{i,j} $</b> relacionado a dummy edge <b>$ E_{i,j} $</b> é menor de <b>$ α $</b> e <b>$ i $</b> e <b>$ j $</b> têm intenções iguais, elemine <b>$ j $</b> e a aresta que conecta ele à intenção e todas as arestas que conectam os vértices que são da mesma conversa que <b>$ i $</b> a <b>$ j $</b>.   \n",
    "\n",
    "\n",
    "2. Reconstruir as arestas da entrada e saída desses vértices:\n",
    "\n",
    "     -- Conecte a entrada de <b>$ j $</b> a <b>$ i $</b> sem nenhuma mudança em peso <br>\n",
    "     -- conecte <b>$ i $</b> aos filhos (que não são intenções) de <b>$ j $</b> e atualize os pesos de forma: \n",
    "     $$ W_{i,k} = W_{i,j} * W_{j,k} $$\n",
    "     \n",
    "Como pode-se ver na figura.b, vértices 3 e 5 têm intenções iguais. Se $ d_{i,j} < α $ podemos eliminar 5 e atualizar os pesos. Caso <b>$ j $</b> a <b>$ i $</b> estejam apontando para mesmo vértice, atualizamos a aresta com peso menor. \n",
    "É importante mencionar que nesse processo somente ajustamos os pesos das dummy edges e os pessos das arestas originais permanecem 1.\n",
    "\n",
    "<img src=\"Img/img08.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Joining similar nodes\n",
    "counter = 0\n",
    "singleNodeDistances = []\n",
    "for distance in usersMessagesDistances:\n",
    "    if(counter <= 10000):\n",
    "        nodeSpec = distance.split(\"(\")[1].split(\",\")\n",
    "        ## If the distance is 0, it means that two questions are exactly the same\n",
    "        if(nodeSpec[0]==\"0\"):\n",
    "            singleNodeDistances.append(float(nodeSpec[2].split(\")\")[0]))\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como aprender esse grafo?\n",
    "\n",
    "A ideia pricipal é aprender as distâncias de passeios aleatóries entre os vértices do grafo.\n",
    "\n",
    "Calculamos as distâncias de passeio aleatório por meio da seguinte fórmula:\n",
    "\n",
    "$$ d(v_{i},v_{j}) = \\sum_{\\tau:v_{i\\hookrightarrow}v_{j}}{p_{v_{i},v_{j}}(\\tau)c(1-c)^{\\tau}} $$ onde $ \\tau $ é o probabilidade do passeio aleatório chegar de $ v_{i} $ a $ v_{j} $, $ c $ é a probabilidade de volta para $ v_{i} $. Vamos fixar um número pequeno para probabilidade de volta. Definimos $ p(\\tau) $ como:\n",
    "\n",
    "$$ p_{v_{i},v_{j}}=\\frac{W_{i,j} }{\\sum W_{vizinhos}} $$\n",
    "\n",
    "\n",
    "Assim criamos uma apresentação vetorial de todas as distâncias onde cada distância representa um feature do grafo. A seguir vamos criar uma apresentação vetorial de um grafo simples:\n",
    "\n",
    "<img src=\"Img/Img09.png\">\n",
    "\n",
    "Antes vamos dar alguns valores às distâncias semânticas entre os vértices:\n",
    "\n",
    "$d_{1,4} = 0.4 $ , $d_{1,5} = 9 $, $d_{2,4} = 3 $, $d_{2,5} = 11 $, $d_{3,4} = 5 $, $d_{3,5} = 0.2 $\n",
    "\n",
    "Os pesos relacionados às arestas originais têm peso de 1. Assim:\n",
    "\n",
    "$W_{1,1} = 0 $\n",
    "$W_{1,2} = 1 $\n",
    "$W_{1,3} = 0 $\n",
    "$W_{2,1} = 0 $ <br>\n",
    "$W_{2,2} = 0 $\n",
    "$W_{2,3} = 1 $\n",
    "$W_{3,1} = 0 $ <br>\n",
    "$W_{3,2} = 0 $\n",
    "$W_{3,3} = 0 $\n",
    "\n",
    "e os pesos entre dummy edges são calculados como seguinte:\n",
    "\n",
    "$W_{1,4} = 1 - \\frac{d_{1,4}}{ 11 = D} = 1 - \\frac{0.4}{11} = 0.96 $ <br> \n",
    "$W_{1,5} = 1 - \\frac{d_{1,5}}{ 11 = D} = 1 - \\frac{9}{11} = 0.19 $ <br> \n",
    "$W_{2,4} = 1 - \\frac{d_{2,4}}{ 11 = D} = 1 - \\frac{3}{11} = 0.73 $ <br> \n",
    "$W_{2,5} = 1 - \\frac{d_{2,5}}{ 11 = D} = 1 - \\frac{11}{11} = 0 $ <br> \n",
    "$W_{3,4} = 1 - \\frac{d_{3,4}}{ 11 = D} = 1 - \\frac{5}{11} = 0.65 $ <br> \n",
    "$W_{3,5} = 1 - \\frac{d_{3,5}}{ 11 = D} = 1 - \\frac{0.2}{11} = 0.98 $ <br>\n",
    "\n",
    "Como pode-se ver, para os vértices que semanticamente são mais parecidos, a probabilidade de transição é mais alta do que os vértices que são semanaticamente mais longes.\n",
    "\n",
    "Vamos fixar $ \\tau = 2 $ e $ c = 0.0002 $. Assim vamos calcular a distância baseado em passeios alearórios de tamanho 2. Mostramos essas distâncias com $ d_{rw}(v_{i}, v_{j})$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ d_{rw}(v_{1}, v_{2}) =  \\sum_{\\tau=1}^{2} c(1-c) P_{v_{1}, v_{2}} = (0.0002 \\times 0.998 \\times  \\frac{1}{1+1+(W_{1,4}=0.96)}) + (0.0002) \\times 0.998 \\times (p_{1,4}=\\frac{0.96}{1+1+(W_{1,4}=0.96)}) \\times (p_{2,4}=\\frac{0.73}{1+1+(W_{1,4}=0.96 + W_{2,4}=0.73 + W_{2,4}=0.65)}) = 0.00001 $\n",
    "\n",
    "Assim, calculamos as distâncias para todos os vértices e formamos uma respresentação vetorial do grafo.\n",
    "\n",
    "<img src=\"Img/Img10.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
